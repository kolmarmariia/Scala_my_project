{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лаба 4b. Обучение и инференс с использованием SparkML, sci-kit learn.\n",
    "Дедлайн\n",
    "⏰ 21 июня 2021 года, 23:59.\n",
    "\n",
    "------------------------\n",
    "Данная работа может быть сделана 2 способами:\n",
    "\n",
    "Простой способ. Реализация работы на SparkML с базовыми трансформерами и эстиматорами.\n",
    "\n",
    "Усложненный способ. Реализация работы на Spark ML с пользовательскими трансформерами и эстиматорами и подключением кода обучения модели на питоне. Дело тут вот в чем. SparkML - довольно ограниченная библиотека, по крайней мере с точки зрения дата-сайентиста. В ней нет многих алгоритмов, к которым привыкли ДС. Однако спарк обладает несомненным преимуществом в параллельной обработке большого количества данных. А так же разработчики спарка дали возможность расширять библиотеку собственными классами. Это позволит объединить оба мира, взяв от каждого лучшее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача с высоты птичьего полета.\n",
    "Обучите модель <b>LogisticRegression</b> на датасете weblogs, используя SparkML и Pipeline.\n",
    "\n",
    "Разработайте приложение на Spark для инференса тестового датасета из Kafka, используя Spark Structured Streaming.\n",
    "\n",
    "Если Вы решили реализовывать собственные трансформеры и эстиматоры и глубже разобраться как работает SparkML под капотом, то:\n",
    "\n",
    "Добавьте в этот пайплайн собственноручно написанный класс-трансформер для преобразования url в domain.\n",
    "\n",
    "Напишите собственный класс-эстиматор. В этом эстиматоре в методе fit() вы будете вызывать программу для обучения модели на питоне с использованием sklearn, в которой подаются данные для обучения, а обученную модель вы сохраняете в переменной класса. В методе transform() вы тоже будете вызывать питоновский скрипт, применяющий модель sklearn для предсказаний.\n",
    "\n",
    "Обученный пайплайн сохраняется на диск обычным образом. Далее вы применяете тот же самый код для инференса.\n",
    "\n",
    "Такой вариант может показаться спорным, ведь питоновская программа для обучение должна запускаться один раз на драйвере, и будет ограничена по памяти, то есть ей придется давать датасет небольшого размера. Но на практике это не так страшно - сэмплируют небольшой датасет из большого и это не приводит к существенной потере качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.math.max\n",
    "import org.apache.spark.rdd.RDD\n",
    "import scala.io.Source\n",
    "import java.io._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.mllib.linalg.distributed._\n",
    "import org.apache.spark.ml.linalg.{SparseVector, Vector}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.ml.feature._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{CountVectorizer, StringIndexer, IndexToString}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@31ae15ab\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@31ae15ab"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "   .builder()\n",
    "   .appName(\"makoles lab4b\")\n",
    "   .config(\"spark.executor.instances\", \"16\")\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Описание данных\n",
    "Обучающая выборка, с которой вы будете работать, выглядит следующим образом (датасет weblogs (путь на hdfs: /labs/slaba04b/laba04b.json), в котором добавлены метки класса для обучения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_set = [gender_age: string, uid: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[gender_age: string, uid: string ... 1 more field]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_set = spark.read.json(\"/labs/slaba04b/laba04b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender_age: string (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- visits: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- timestamp: long (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|gender_age|                 uid|              visits|\n",
      "+----------+--------------------+--------------------+\n",
      "|   F:45-54|0dce7423-1f2e-4db...|[[1419604951975, ...|\n",
      "|   M:25-34|0dcf8ee3-6b33-457...|[[1419869055980, ...|\n",
      "|   M:45-54|0dd1aa68-b788-414...|[[1427117036000, ...|\n",
      "+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set.limit(3).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле uid принимает значения уникального ID пользователя (cookies): d50192e5-c44e-4ae8-ae7a-7cfe67c8b777."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_set_pars_visit = [uid: string, gender_age: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, gender_age: string ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_set_pars_visit=data_set\n",
    "    .withColumn(\"visit\",explode('visits))\n",
    "    .drop(\"visits\")\n",
    "    .withColumn(\"url\",col(\"visit.url\"))\n",
    "    .select('uid,'gender_age, 'url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регулярное выражение для обрезки домена из url адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_re = ^http(s)?(%3A|:)(//|%2F%2F)(www\\.)?(([\\%a-zA-Zа-яА-Я0-9-]+\\.)+[\\%a-zA-Zа-яА-Я0-9-]+)\\.?/.*$\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "^http(s)?(%3A|:)(//|%2F%2F)(www\\.)?(([\\%a-zA-Zа-яА-Я0-9-]+\\.)+[\\%a-zA-Zа-яА-Я0-9-]+)\\.?/.*$"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val new_re = \"\"\"^http(s)?(%3A|:)(//|%2F%2F)(www\\.)?(([\\%a-zA-Zа-яА-Я0-9-]+\\.)+[\\%a-zA-Zа-яА-Я0-9-]+)\\.?/.*$\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_set_domain = [uid: string, gender_age: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, gender_age: string ... 1 more field]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_set_domain=data_set_pars_visit\n",
    "    .withColumn(\"domain\", regexp_extract(concat(regexp_replace('url, \"%2F\", \"/\"), lit(\"/\")), new_re, 5))\n",
    "    .filter('domain !== \"\")\n",
    "    .select('uid,'gender_age, 'domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_set_group = [gender_age: string, uid: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[gender_age: string, uid: string ... 1 more field]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_set_group=data_set_domain\n",
    "    .groupBy(data_set_domain(\"gender_age\"), data_set_domain(\"uid\"))\n",
    "    .agg(collect_list(data_set_domain(\"domain\")).alias(\"domains\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv = cntVec_f95528cb218e\n",
       "indexer = strIdx_c3a38b5429e9\n",
       "lr = logreg_360325ee4624\n",
       "labels = Array(M:25-34, F:25-34, M:35-44, F:35-44, F:18-24, F:45-54, M:45-54, M:18-24, F:>=55, M:>=55)\n",
       "converter = idxToStr_cad51441b39f\n",
       "pipeline = pipeline_2585360ad4ef\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_2585360ad4ef"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cv = new CountVectorizer()\n",
    "      .setInputCol(\"domains\")\n",
    "      .setOutputCol(\"features\")\n",
    "\n",
    "val indexer = new StringIndexer()\n",
    "      .setInputCol(\"gender_age\")\n",
    "      .setOutputCol(\"label\")\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "      .setMaxIter(32)\n",
    "      .setRegParam(0.000001)\n",
    "      .setElasticNetParam(0.2)\n",
    "\n",
    "val labels = indexer.fit(data_set_group).labels\n",
    "\n",
    "val converter = new IndexToString()\n",
    "  .setInputCol(\"prediction\")\n",
    "  .setLabels(labels)\n",
    "  .setOutputCol(\"res\")\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(cv, indexer, lr, converter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_2585360ad4ef\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_2585360ad4ef"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(data_set_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_predictions = [gender_age: string, uid: string ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[gender_age: string, uid: string ... 7 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val train_predictions = model.transform(data_set_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-------+\n",
      "|gender_age|                 uid|             domains|            features|label|       rawPrediction|         probability|prediction|    res|\n",
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-------+\n",
      "|   F:18-24|d50192e5-c44e-4ae...|[zebra-zoya.ru, n...|(107846,[103,5325...|  4.0|[-3.5707225774695...|[1.28722821284297...|       4.0|F:18-24|\n",
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions.filter('uid === \"d50192e5-c44e-4ae8-ae7a-7cfe67c8b777\").show(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+\n",
      "|gender_age|res_correct|count|\n",
      "+----------+-----------+-----+\n",
      "|   F:18-24|          0|  633|\n",
      "|   F:18-24|          1| 2252|\n",
      "|   F:25-34|          0|  728|\n",
      "|   F:25-34|          1| 6061|\n",
      "|   F:35-44|          0|  695|\n",
      "|   F:35-44|          1| 3576|\n",
      "|   F:45-54|          0|  534|\n",
      "|   F:45-54|          1| 2063|\n",
      "|    F:>=55|          0|  192|\n",
      "|    F:>=55|          1|  703|\n",
      "|   M:18-24|          0|  391|\n",
      "|   M:18-24|          1| 1621|\n",
      "|   M:25-34|          0|  773|\n",
      "|   M:25-34|          1| 7893|\n",
      "|   M:35-44|          0|  712|\n",
      "|   M:35-44|          1| 4373|\n",
      "|   M:45-54|          0|  342|\n",
      "|   M:45-54|          1| 1804|\n",
      "|    M:>=55|          0|  122|\n",
      "|    M:>=55|          1|  660|\n",
      "+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions.withColumn(\"res_correct\", expr(\"case when res = gender_age then 1 else 0 end\"))\n",
    ".groupBy('gender_age, 'res_correct)\n",
    ".count()\n",
    ".orderBy('gender_age, 'res_correct).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"model_lab04b.ml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark-master-1.newprolab.com:6667\n",
    "spark-node-1.newprolab.com:2181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_in = maria_kolesnikova\n",
       "topic_out = maria_kolesnikova_lab04b_out\n",
       "kafka_bootstrap = spark-master-1:6667\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spark-master-1:6667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val topic_in = \"maria_kolesnikova\"\n",
    "val topic_out = \"maria_kolesnikova_lab04b_out\"\n",
    "val kafka_bootstrap = \"spark-master-1:6667\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задали схему для потока из Кафки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(uid,StringType,true), StructField(visits,ArrayType(StructType(StructField(timestamp,LongType,true), StructField(url,StringType,true)),true),true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(uid,StringType,true), StructField(visits,ArrayType(StructType(StructField(timestamp,LongType,true), StructField(url,StringType,true)),true),true))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(Seq(\n",
    "  StructField(\"uid\", StringType, true),\n",
    "  StructField(\"visits\", ArrayType(StructType(Seq(StructField(\"timestamp\",LongType,true), StructField(\"url\", StringType, true))), true), true)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url2domain: (url: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.net.URL\n",
    "import java.net.URI\n",
    "import util.Try\n",
    "import java.net.MalformedURLException\n",
    "def url2domain (url: String) : String = {\n",
    "    var res_domain = \"\"\n",
    "    try {\n",
    "        res_domain = new URL(url).getHost\n",
    "    } catch {\n",
    "            case e: MalformedURLException => res_domain = new URI(url.replace(\" \", \"\")).getHost\n",
    "    }\n",
    "    res_domain\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "www.toysrus.com"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2domain(\"http://www.toysrus.com/category/index.jsp?categoryid=57525526&sr=1&origkw=monster high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "converturls: org.apache.spark.sql.expressions.UserDefinedFunction\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def converturls = udf { (url_arr: Seq[Row]) => \n",
    "    url_arr.map(x => url2domain(x.getAs[String](\"url\")) ).distinct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_in = [uid: string, domains: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, domains: array<string>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_in = spark\n",
    "    .readStream \n",
    "    .format(\"kafka\") \n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint-aokorogo-read\") \n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap) \n",
    "    .option(\"subscribe\", topic_in) \n",
    "    .option(\"startingOffsets\", \"latest\") \n",
    "    .option(\"failOnDataLoss\", false)\n",
    "    .load()\n",
    "    .selectExpr(\"CAST(value AS STRING)\")\n",
    "    .withColumn(\"jsonData\", from_json(col(\"value\"), schema))\n",
    "    .select(\"jsonData.*\")\n",
    "    .select('uid, converturls(col(\"visits\")).alias(\"domains\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- domains: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results = [uid: string, domains: array<string> ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, domains: array<string> ... 5 more fields]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model.transform(df_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- domains: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- res: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_out = [uid: string, gender_age: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[uid: string, gender_age: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_out = results\n",
    "    .withColumnRenamed(\"res\", \"gender_age\")\n",
    "    .select(\"uid\", \"gender_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@61039bdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@61039bdf"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val query = df_out\n",
    "    .select(to_json(struct(\"uid\", \"gender_age\")).alias(\"value\"))\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .format(\"kafka\")\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint-write\")\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap )\n",
    "    .option(\"topic\", topic_out)\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
